{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 4 -- Applying Machine Learning Algorithms\n",
    "\n",
    "You will be given a data set, and will apply the techniques we have studied in class to predict a numeric response variable, and to evaluate alternative solutions.\n",
    "\n",
    "The steps will be\n",
    "\n",
    "1.  Exploratory data analysis and evaluation\n",
    "  * Find and correct outliers and missing values\n",
    "  * Find nonlinear relationships between the independent variables and the dependent variable, and transform the input appropriately\n",
    "  * Find correlation in the independent variables and decide how if at all to address it\n",
    "  \n",
    "\n",
    "2. Apply learning techniques.  In each case you will train the algorithm and evaluate it using the *test* $R^2$ statistic.  You will explore different hyperparameter values to find the model you think will maximize test $R^2$ for an evaluation data set.  You will do this for\n",
    "  * Linear regression exploring different variable sets using regular stepwise regression, Lasso, and Ridge Regression\n",
    "  * Decision tree regression exploring different tree depths\n",
    "  * Random forests and boosting exploring different parameter sets\n",
    "  * Neural networks \n",
    "\n",
    "\n",
    "3. Choosing the best method.  You will choose one algorithm and parameter settings you are most confident with, and write a function that enables it to evaluate a new data set.\n",
    "\n",
    "4. When I evaluate your solution, I will call this function on a new set of data, and score your solution (partially) on its results\n",
    "\n",
    "Every part of this assignment has been covered in the notebooks we have looked at in class, so that should be your first source of information and inspiration. \n",
    "\n",
    "<b><span style=\"color: blue\">Cells in blue indicate you should fill in your results -- either text or code.</span></b>\n",
    "\n",
    "When you submit your code, please fill in the cells asked for, but do not add new cells or change the other cells.\n",
    "\n",
    "I will run the cells in your submitted notebook in sequence, so make sure things are in the proper order, all the needed libraries have been imported, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "#### Note on your prediction functions\n",
    "\n",
    "You will notice that for each technique, you are asked to provide a \"prediction\" function that takes an **X** matrix as input.  This **X** matrix will be in the format of the original data set you loaded.  So if in your data cleaning phase you added or deleted or transformed column values, each of these prediction functions must make the same transformations on its input prior to calling you model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------\n",
    "\n",
    "### Loading and Cleaning the Data Set\n",
    "\n",
    "The data set is in a file named **data_set.csv** -- it has 11 independent variables -- some are numeric and some categorical -- and a single numeric response variable $y$.\n",
    "\n",
    "In the first cleaning / analysis phase you should do the following\n",
    "1. Look for outlier values.  When you find outliers, you can do one of two things\n",
    "  * Throw away the data row altogether.  If many variables in the row seem uncommon, it is probably best to delete the row.\n",
    "  * Replace the outlier with a \"reasonable\" value -- probably the mean or median value for that variable.   The reasoning is that the benefit of keeping the row outweighs the error introduced by having a made-up value in one variable\n",
    "2. Look for missing values.  Most algorithms will throw away data rows that have *any* missing value.  You can just delete the row (especially if many values are missing) or assign it a \"reasonable\" value -- probably the mean value for that variable.  If there is an attribute that has many missing values, it is probably best to delete the whole column\n",
    "3. Look for nonlinear relationships.   Most important is finding nonlinear relationships between one of the $x$ variables, and the $y$ variable.  For example, maybe $y$ depends on $x^2$ or $\\log(x)$ rather than on $x$. In that case you need to guess at that relationship, and replace $x$ with a transformed value.  For example if it looks like $y$ depends on $x^2$ then just a column of $x^2$ values.  The easiest way to see these relationships is to do a pair plot between your X variables and y, including a trend line.  \"Well behaved\" $x$ variables tend to show no pattern except for (roughly) following the trend line.  If you are seeing other shapes, or sudden jumps in the behavior of $y$ as $x$ changes, something nonlinear is going on.\n",
    "4. Look for correlations among the $x$ variables.  If you find a correlation you may want to delete one of the correlated variables, but it is not necessary -- you will have to experiment to see if it improves your predictions.  To find correlations, you can use the pair plot, or a correlation matrix, or a heatmap -- there are examples of all of these in the class notebooks.\n",
    "5. Transform categorical variables to dummy (0/1 coded) variables\n",
    "\n",
    "The result of this phase should be a matrix ${\\bf X}$ and a vector ${\\bf y}$ that comprise your training set.\n",
    "\n",
    "Remember though, if you ever need to use your learned function to a new ${\\bf X}$ data set, you need to transform the input ${\\bf X}$ matrix the same way your transformed your test set -- otherwise your learned function will give bad results.\n",
    "\n",
    "Although it looks like this cleaning phase happens before any analysis/learning, the two processes are interleaved.  Start with a simple linear regression model and do minimal cleaning on your data set, just to the point the LR model works.  Then you can test more subtle transformations to see if they make your models perform better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "\n",
    "# Get rid of rows with invalid values\n",
    "def correctDummies(df):\n",
    "    df = df[df.x4.isin(['true', 'false'])]\n",
    "    df = df[df.x2.isin(['r', 'b', 'y'])]\n",
    "    return df\n",
    "\n",
    "#  Add the dummy variables and get rid of x2 and x4.   Has to be done after correctDummies!\n",
    "def convertDummies(df):\n",
    "    dfnew = df.copy()\n",
    "    x2_dummies = pd.get_dummies(dfnew.x2, prefix='x2')\n",
    "    x4_dummies = pd.get_dummies(dfnew.x4, prefix='x4')\n",
    "    x2_dummies.drop(x2_dummies.columns[0], axis=1, inplace=True)\n",
    "    x4_dummies.drop(x4_dummies.columns[0], axis=1, inplace=True)\n",
    "    dfnew.drop(['x2', 'x4'], axis=1, inplace=True)\n",
    "    dfnew = pd.concat([dfnew, x2_dummies], axis=1)\n",
    "    dfnew = pd.concat([dfnew, x4_dummies], axis=1)\n",
    "    return dfnew\n",
    "\n",
    "def remove_outliers(data):\n",
    "    for name in list(data.columns):\n",
    "        if is_numeric_dtype(data[name]):\n",
    "            data = data[np.abs(data[name]-data[name].mean()) < (3*data[name].std())]\n",
    "    return data\n",
    "\n",
    "def remove_missing_values(data):\n",
    "    data.dropna(inplace=True)\n",
    "    return data \n",
    "\n",
    "def update_nonlinear_values(data):\n",
    "    data.x8 = data.x8**2\n",
    "    return data\n",
    "\n",
    "def separate_column_values(data):\n",
    "    data['x5_b'] = data['x5'] >= data_x5_mean\n",
    "    data['x5_s'] = data['x5'] < data_x5_mean\n",
    "    data['x5_b'] = data['x5_b'].astype(int)*data['x5']\n",
    "    data['x5_s'] = data['x5_s'].astype(int)*data['x5']\n",
    "    data.drop(['x5'], axis=1, inplace=True)\n",
    "    return data\n",
    "\n",
    "def deal_with_unordered_categories(data):\n",
    "    for name in list(data.columns):\n",
    "        if not is_numeric_dtype(data[name]):\n",
    "            temp_dummies = pd.get_dummies(data[name], prefix=name)\n",
    "            temp_dummies.drop(temp_dummies.columns[0], axis=1, inplace=True)\n",
    "            data.drop(name, axis=1, inplace=True)\n",
    "            data = pd.concat([data, temp_dummies], axis=1)\n",
    "    return data\n",
    "\n",
    "def cleandf(df):\n",
    "    df = df.dropna(inplace=False)\n",
    "    df = update_nonlinear_values(df)\n",
    "    df = separate_column_values(df)\n",
    "    df = correctDummies(df)\n",
    "    df = convertDummies(df)\n",
    "    return df\n",
    "\n",
    "file_location = 'data_set.csv'\n",
    "df = pd.read_csv(file_location, dtype={'x4': str})\n",
    "df = remove_outliers(df)\n",
    "data_x5_mean = df.x5.mean()\n",
    "df = cleandf(df)\n",
    "y = df.y\n",
    "X = df.drop(['y'], axis=1, inplace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------\n",
    "#### <span style=\"color: blue\">*Your Summary of EDA / Cleaning Phase*</span>\n",
    "\n",
    "<span style=\"color: blue\">\n",
    "\n",
    "*In this markdown cell please write up the transformations you made to the data set, and why you decided to make those transformations.*\n",
    "1. Look for outlier values: If the differences between an individual value and the mean in a column are equal or greater than three times of standard deviation of the column, remove the data.<br><br>\n",
    "\n",
    "2. Look for missing values and correct the values: If a missing value exists in a data, just remove this data. Here, only keep values with 'r', 'b', 'y' in 'x2' column and keep values with 'true' and 'false' in 'x4' column. Others are removed.<br><br>\n",
    "\n",
    "3. Look for nonlinear relationships: After checking the pair plot between X variables and y, I only found that 'y' should depend on 'x8'^2. So, I add \"data.x8 = data.x8^2\". Also, 'x5' needs to separate two columns,'x5_b' and 'x5_s', by the mean value because there are two tendenies within this column.<br><br>\n",
    "\n",
    "4. Look for correlations among the 𝑥 variables: After checking the correlation among these x variables, I only found 'x6' and 'x7' have a very high correlation(~0.968). However, after I run all the regressions, the results of keeping both in the X variables is better than removing it. So, I keep both variables in the data set and leave them to the regreesion models to judge\".<br><br>\n",
    "\n",
    "5. Transform categorical variables to dummy (0/1 coded) variables: Only tranform 'x2' and 'x4' to dummy variables.\n",
    "\n",
    "</span>\n",
    "\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following cells you will try various learning techniques on your data set.  For each one you will finish with a prediction function for your best model.  For example for linear regression you will define a function **linear_regression_predict(X)** which will produce the predicted $y$ values for your model.  Remember that the **X** argument is un-transformed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------\n",
    "### Linear Regression\n",
    "\n",
    "In this section you will try linear regression, and also use Lasso, Ridge Regression and Forward Stepwise Regression to find the set of variables that give you the best $R^2$ score.   You will produce a markdown summary, then implementations of your four models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### <span style=\"color: blue\">Summary of Your Linear Regression Models</span>\n",
    "<span style=\"color: blue\">\n",
    "In this markdown cell, summarize your results in building linear regression models for this data set.\n",
    "For each method (full-model regression, forward stepwise regression, Lasso, and Ridge regression) report on the best model:  the variables in the model, the adjusted $R^2$, the estimated test accuracy, and in the case of Lasso, the optimal $\\alpha$ value.  Can you explain the differences in the structure and performance of the alternative models?\n",
    "    \n",
    "1. Full-model regression: (using GridSearchCV)<br>\n",
    "   Variables: 'x1', 'x3', 'x6', 'x7', 'x8', 'x9', 'x10', 'x11', 'x5_b', 'x5_s', 'x2_r', 'x2_y', 'x4_true'<br>\n",
    "   Adjusted R2: 0.961<br>\n",
    "   Estimated test accuracy: 275849306.98 (MSE)<br>\n",
    "2. Forward stepwise regression: <br> \n",
    "   Selected variables: 'x5_b', 'x1', 'x8', 'x3', 'x2_r', 'x2_y', 'x5_s'<br>\n",
    "   Adjusted R2: 0.961<br>\n",
    "   Estimated test accuracy: 275889252.69 (MSE)<br>\n",
    "3. Lasso regression:<br> (using GridSearchCV)\n",
    "   best 𝛼: 0.1<br>\n",
    "   Adjusted R2: 0.961<br>\n",
    "   Estimated test accuracy: 275849778.72 (MSE)<br>\n",
    "4. Ridge regression:<br> (using GridSearchCV)\n",
    "   best 𝛼: 1.0<br>\n",
    "   Adjusted R2: 0.961<br>\n",
    "   Estimated test accuracy: 275849310.36 (MSE)<br>\n",
    "   \n",
    "All the results are almost same. It is difficult to tell that a particular regression is the best one. In the regression structure, the major difference between full-model and forward stepwise regression is using different set of variables (full-model uses all 13 variables, and forward stepwise uses 6 variables). As for lasso and ridge regression, if I only think about the result and the implementation, the main difference between them is only the function name in the implementation. Both are using 𝛼 as their parameters.\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression()\n",
    "lr.fit(X, y)\n",
    "\n",
    "def linear_regression_predict(xdf):\n",
    "    return lr.predict(xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "def forward_selected(data, response):\n",
    "    remaining = set(data.columns)\n",
    "    remaining.remove(response)\n",
    "    selected = []\n",
    "    current_score, best_new_score = 0.0, 0.0\n",
    "    while remaining and current_score == best_new_score:\n",
    "        scores_with_candidates = []\n",
    "        for candidate in remaining:\n",
    "            formula = \"{} ~ {} + 1\".format(response,' + '.join(selected + [candidate]))\n",
    "            score = smf.ols(formula, data).fit().rsquared_adj\n",
    "            scores_with_candidates.append((score, candidate))\n",
    "        scores_with_candidates.sort()\n",
    "        best_new_score, best_candidate = scores_with_candidates.pop()\n",
    "        if current_score < best_new_score:\n",
    "            remaining.remove(best_candidate)\n",
    "            selected.append(best_candidate)\n",
    "            current_score = best_new_score\n",
    "    formula = \"{} ~ {} + 1\".format(response,' + '.join(selected))\n",
    "    model = smf.ols(formula, data).fit()\n",
    "    return model, selected\n",
    "\n",
    "fsmodel, _ = forward_selected(df, 'y')\n",
    "\n",
    "def stepwise_regression_predict(xdf):\n",
    "    return fsmodel.predict(xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "best_alpha = 0.1\n",
    "lasso = linear_model.Lasso(alpha=best_alpha)\n",
    "lasso.fit(X, y)\n",
    "\n",
    "def lasso_predict(xdf):\n",
    "    return lasso.predict(xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "best_alpha = 1.0\n",
    "ridge = linear_model.Ridge(alpha=best_alpha)\n",
    "ridge.fit(X, y)\n",
    "\n",
    "def ridge_predict(xdf):\n",
    "    return ridge.predict(xdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------\n",
    "### Decision Tree Regressors and Ensemble Methods\n",
    "\n",
    "Here you will build decision tree regression learners, and experiment to optimize algorithm parameters.  You will implement learners for \n",
    "* Decision trees\n",
    "* Random forest\n",
    "* Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: blue\">Summary of Your Decision Tree and Ensemble Method Models</span>\n",
    "<span style=\"color: blue\">\n",
    "In this markdown cell, summarize your results in building tree-based models for this data set.\n",
    "For each method report on the best model:  the model parameters and the estimated test accuracy.<br>\n",
    "1. Decision Tree:<br>\n",
    "   Model parameters: Best depth = 9<br>\n",
    "   Adjusted R2: 0.969<br>\n",
    "   Estimated test accuracy: 216644138.99 (MSE)<br><br> \n",
    "2. Random Forest:<br>\n",
    "   Model parameters: Best n_estimators = 200, Best max_features = 13\n",
    "<br>\n",
    "   Adjusted R2: 0.995<br>\n",
    "   Estimated test accuracy: 37983485.32 (MSE)<br><br>\n",
    "3. Boosting:<br>\n",
    "   Model parameters: Best estimators = 200, Best learning rate = 1.0 <br>\n",
    "   Adjusted R2: 0.916<br>\n",
    "   Estimated test accuracy: 591237762.77 (MSE)\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "best_depth = 9\n",
    "dtree = tree.DecisionTreeRegressor(max_depth = best_depth)\n",
    "dtree.fit(X, y)\n",
    "def decision_tree_predict(xdf):\n",
    "    return dtree.predict(xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "best_n_estimators, best_max_features = 200, 13\n",
    "forest = RandomForestRegressor(n_estimators=best_n_estimators,\n",
    "                                       max_features=best_max_features)\n",
    "forest.fit(X,y)\n",
    "def random_forest_predict(xdf):\n",
    "    return forest.predict(xdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "best_n_estimators, best_learning_rate = 200, 1.0\n",
    "booster = AdaBoostRegressor(n_estimators=best_n_estimators, \n",
    "                                    learning_rate=best_learning_rate)\n",
    "booster.fit(X,y)\n",
    "def adaboost_predict(xdf):\n",
    "    return booster.predict(xdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------\n",
    "### Neural Networks\n",
    "\n",
    "For this part you will use the *keras* library to implement a neural net regression function.  You will experiment with the structure of the network to optimze for $R^2$.  Remember that your neural net implements a *predict* method, and you can use *sklearn.metrics.r2_score* to evaluate your model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <span style=\"color: blue\">Summary of Neural Network Solution</span>\n",
    "<span style=\"color: blue\">\n",
    "In this markdown cell, summarize your results in building the neural network predictor, including the estimated test accuracy and the model parameterers<br>\n",
    "\n",
    "Adjusted R2: 0.961<br>\n",
    "Estimated test accuracy: 276246803.38 (MSE)<br><br>\n",
    "Model parameters:\n",
    "* One input layer with 13 inputs and 50 outputs.<br>\n",
    "* Two hidden layers with 50 nodes.<br>\n",
    "* One output layer with 50 inputs and 1 output.<br>\n",
    "optimizer='adam', loss='mean_squared_error',epochs=200,validation_split=0.1<br>\n",
    "* Using earlystop callback function:<br>\n",
    "monitor='loss', min_delta=0.0000, patience=9, mode='auto', restore_best_weights=True<br>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(50, activation='relu', input_shape = (X.shape[1],)))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer=\"adam\", loss='mean_squared_error')\n",
    "earlystop = EarlyStopping(monitor='loss', min_delta=0.0000, patience=9, verbose=0, mode='auto', restore_best_weights=True)\n",
    "callbacks_list = [earlystop]\n",
    "model.fit(X, y, epochs=200, callbacks=callbacks_list, verbose=0);\n",
    "\n",
    "def neural_net_predict(xdf):\n",
    "    return model.predict(xdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring Your Work\n",
    "In the following code cell, implement a method best_model_predict(X) where X is the same shape as the original training set in the data file.  I will call this function on a new data set generated by the same function, but not part of the training set.  Use whatever method and parameter settings you think will perform best.   **Remember** the ${\\bf X}$ matrix I will call your predict function with will be like the original data matrix, so if you did any transformations on the data set, you will have to do transformation on this matrix too.  It is guaranteed that the data set I used will not have any missing values or deliberate outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_model_predict(x_matrix):\n",
    "    \n",
    "    return random_forest_predict(x_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linear_regression': 6.61, 'stepwise_regression': 6.612, 'lasso_regression': 6.618, 'ridge_regression': 6.61, 'decision_tree_regression': 5.117, 'random_forest_regression': 2.018, 'adaboost_regression': 18.21, 'neural_net_regression': 7.09}\n"
     ]
    }
   ],
   "source": [
    "## I will copy code into this cell which will (a) read in the evaluation data frame, \n",
    "## (b) call your predict function, and (c) compute a score for your model on my evaluation data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
